---
title: "Q1"
format: pdf
editor: visual
---

## Q1A:

```{r}
load("Q1A.Rdata")
obj <- load("Q1A.Rdata")
# obj
# head(df, 200)
```

```{r}
set.seed(123457)
train.prop <- 0.80
trnset <- sort(sample(1:nrow(df), ceiling(nrow(df)*train.prop)))

train.set <- df[trnset, ]
test.set  <- df[-trnset, ]
```

```{r}
library(caret)

contpredcols <- 2:101
keepcols <- c("y")

normParam <- preProcess(train.set[, contpredcols],method = c("center", "scale"))

data.train <- cbind(train.set[, keepcols, drop = FALSE],predict(normParam, train.set[, contpredcols]))
data.test <- cbind(test.set[, keepcols, drop = FALSE],predict(normParam, test.set[, contpredcols]))


```

**Lasso Regression:**

```{r}
library(glmnet)

X <- model.matrix(y ~ . - 1, data = data.train)
y <- data.train$y

cvfit <- cv.glmnet(X, y, alpha = 1)
plot(cvfit)
best_lambda <- cvfit$lambda.min
# (cvfit$lambda.min)
lasso_mod <- glmnet(X, y, alpha = 1, lambda = best_lambda)
# coef(lasso_mod)
```

**Full Model Evaluation:**

```{r}
mlr1 <- lm(y ~ X1+X14+X15+X16+X20+X26+X29+X58+X62+X64+X90, data = train.set)
summary(mlr1)
car::vif(mlr1)
```

```{r}
par(mfrow=c(2,2))
plot(mlr1)
```

The fit seems to be very good for such a small dataset. In case we can find an even better model, we will search for high influence points & outliers:

```{r}
y_test_actual <- data.test$y
y_test_pred   <- predict(mlr1, newdata = data.test)

mse_test  <- mean((y_test_actual - y_test_pred)^2)
rmse_test <- sqrt(mse_test)
mae_test  <- mean(abs(y_test_actual - y_test_pred))

rss <- sum((y_test_actual - y_test_pred)^2)
tss <- sum((y_test_actual - mean(y_test_actual))^2)
r2_test <- 1 - rss/tss

test_results <- data.frame(Metric = c("MSE", "RMSE", "MAE", "R-squared"),Value  = c(mse_test, rmse_test, mae_test, r2_test))

print(test_results)

```

#### Code used for analysis:

```{r}
# mlr <- lm(y ~ X1+X14+X15+X16+X20+X26+X29+X51+X58+X62+X64+X90, data = train.set)
# 
# summary(mlr)
```

```{r}
# hist(df$y, breaks=30, main="", xlab="y")
```

```{r}
# #install.packages("ppcor")
# library(ppcor)
# car::vif(mlr) 
# 
# #install.packages("olsrr")
# library(olsrr)
# (mod.condind <- ols_eigen_cindex(mlr)[,2])
# (mod.condnum <- max(mod.condind)/min(mod.condind))
```

```{r}
# y_test_pred_enet <- as.vector(predict(enet, newx = X_test, s = "lambda.min"))
# 
# 
# mse_enet  <- mean((y_test_actual - y_test_pred_enet)^2)
# rmse_enet <- sqrt(mse_enet)
# mae_enet  <- mean(abs(y_test_actual - y_test_pred_enet))
# 
# rss_enet <- sum((y_test_actual - y_test_pred_enet)^2)
# r2_enet  <- 1 - rss_enet/tss
# 
# enet_results <- data.frame(
#   Metric = c("MSE", "RMSE", "MAE", "R-squared"),
#   Value  = c(mse_enet, rmse_enet, mae_enet, r2_enet)
# )
# 
# enet_results
```

```{r}
# y_test_pred_ridge <- as.vector(predict(ridge, newx = X_test, s = "lambda.min"))
# 
# 
# mse_ridge  <- mean((y_test_actual - y_test_pred_ridge)^2)
# rmse_ridge <- sqrt(mse_ridge)
# mae_ridge  <- mean(abs(y_test_actual - y_test_pred_ridge))
# 
# rss_ridge <- sum((y_test_actual - y_test_pred_ridge)^2)
# tss       <- sum((y_test_actual - mean(y_test_actual))^2)
# r2_ridge  <- 1 - rss_ridge/tss
# 
# ridge_results <- data.frame(
#   Metric = c("MSE", "RMSE", "MAE", "R-squared"),
#   Value  = c(mse_ridge, rmse_ridge, mae_ridge, r2_ridge)
# )
# 
# ridge_results
```

```{r}
# mlr <- lm(y ~ ., data = data.train) # mlrint <- lm(y ~ .^2, data = data.train) # summary(mlrint)
# comp <- anova(mlr, mlrint) 
# comp
```

```{r}
# step(lm(y ~ ., data = data.train), scope = ~ ., direction = "both")
```

Lasso:

X1, X14, X15, X16, X20, X26, X29, X51, X58, X62, X64, X90

```{r}
# plot(enet)
# (enet$lambda.min)
# coef(enet, s = "lambda.min")
```

## Q1B

```{r}
load("Q1B.Rdata")
obj <- load("Q1B.Rdata")
obj

# head(df, 200)
```

Training/Test Split:

```{r}
set.seed(1234)
train.prop <- 0.70
trnset <- sort(sample(1:nrow(df), ceiling(nrow(df)*train.prop)))

train.set <- df[trnset, ]
test.set  <- df[-trnset, ]
```

```{r}
library(caret)

contpredcols <- 2:101
keepcols <- c("y")

normParam <- preProcess(train.set[, contpredcols],method = c("center", "scale"))

data.train <- cbind(train.set[, keepcols, drop = FALSE],predict(normParam, train.set[, contpredcols]))
data.test <- cbind(test.set[, keepcols, drop = FALSE],predict(normParam, test.set[, contpredcols]))


```

#### Model:

```{r}
library(glmnet)

X <- model.matrix(y ~ . - 1, data = data.train)
y <- data.train$y

cvfit <- cv.glmnet(X, y, alpha = 1)
plot(cvfit)
best_lambda <- cvfit$lambda.min
(cvfit$lambda.min)
lasso_mod <- glmnet(X, y, alpha = 1, lambda = best_lambda)
coef(lasso_mod)


```

```{r}
mlr <- lm(y ~ X6+X8+X9+X12+X24+X36+X40+X56+X58+X62+X64+X65+X96, data = train.set)

summary(mlr)
```

```{r}
y_test_actual <- data.test$y
y_test_pred   <- predict(mlr, newdata = data.test)

mse_test  <- mean((y_test_actual - y_test_pred)^2)
rmse_test <- sqrt(mse_test)
mae_test  <- mean(abs(y_test_actual - y_test_pred))

rss <- sum((y_test_actual - y_test_pred)^2)
tss <- sum((y_test_actual - mean(y_test_actual))^2)
r2_test <- 1 - rss/tss

test_results <- data.frame(Metric = c("MSE", "RMSE", "MAE", "R-squared"),Value  = c(mse_test, rmse_test, mae_test, r2_test))

print(test_results)


```

#### Code used for analysis:

```{r}
# y_test_pred_ridge <- as.vector(predict(ridge, newx = X_test, s = "lambda.min"))
# 
# 
# mse_ridge  <- mean((y_test_actual - y_test_pred_ridge)^2)
# rmse_ridge <- sqrt(mse_ridge)
# mae_ridge  <- mean(abs(y_test_actual - y_test_pred_ridge))
# 
# rss_ridge <- sum((y_test_actual - y_test_pred_ridge)^2)
# tss       <- sum((y_test_actual - mean(y_test_actual))^2)
# r2_ridge  <- 1 - rss_ridge/tss
# 
# ridge_results <- data.frame(
#   Metric = c("MSE", "RMSE", "MAE", "R-squared"),
#   Value  = c(mse_ridge, rmse_ridge, mae_ridge, r2_ridge)
# )
# 
# ridge_results

```

```{r}
# y_test_pred_enet <- as.vector(predict(enet, newx = X_test, s = "lambda.min"))
# 
# 
# mse_enet  <- mean((y_test_actual - y_test_pred_enet)^2)
# rmse_enet <- sqrt(mse_enet)
# mae_enet  <- mean(abs(y_test_actual - y_test_pred_enet))
# 
# rss_enet <- sum((y_test_actual - y_test_pred_enet)^2)
# r2_enet  <- 1 - rss_enet/tss
# 
# enet_results <- data.frame(
#   Metric = c("MSE", "RMSE", "MAE", "R-squared"),
#   Value  = c(mse_enet, rmse_enet, mae_enet, r2_enet)
# )
# 
# enet_results

```

```{r}
# #install.packages("ppcor")
# library(ppcor)
# car::vif(mlr) 
# 
# #install.packages("olsrr")
# library(olsrr)
# (mod.condind <- ols_eigen_cindex(mlr)[,2])
# (mod.condnum <- max(mod.condind)/min(mod.condind))
```

```{r}
# mlr1 <- lm(y ~ X1+X6+X8+X9+X11+X12+X19+X22+X24+X29+X31+X39+X40+X48+X49+X55+X56+X58+X62+X64+X69+X81+X91+X92+X95+X96+X99, data = train.set)
# summary(mlr1)
# car::vif(mlr1)
```

```{r}
# par(mfrow=c(2,2))
# plot(mlr)
```

```{r}
# y_actual <- data.train$y
# y_pred   <- predict(mlr, newdata = data.train)
# 
# if (is.null(rownames(data.train))) {
#   rownames(data.train) <- 1:nrow(data.train)
# }
# 
# par(mfrow = c(1,1))
# plot(y_actual, y_pred,
#      col = 4, cex = 0.6,
#      xlab = "Actual y",
#      ylab = "Predicted y",
#      axes = FALSE)
# 
# 
# res <- residuals(mlr)
# extpts <- which(abs(res) > 2 * sd(res))
# # 
# # 
# axis(1); axis(2)
# grid()
# abline(0, 1, col = 4, lwd = 2)
```

```{r}
# y_test_actual <- data.test$y
# y_test_pred   <- predict(mlr, newdata = data.test)
# 
# plot(y_test_actual, y_test_pred,
#      col = "purple", cex = 0.6,
#      xlab = "Actual (Test)",
#      ylab = "Predicted (Test)")
# abline(0,1,col="purple",lwd=2)
# grid()


```

```{r}
# par(mfrow=c(1,1))
# 
# plot(rstandard(mlr)^2, hatvalues(mlr),
#      pch = 19, cex = 0.5, col = "blue",
#      xlab = "Squared Standardized Residuals",
#      ylab = "Leverage")

```

```{r}

# ridge <- cv.glmnet(X, y,alpha        = 0,  standardize  = FALSE, type.measure = "mse",nfolds = 10)
# 
# 
# plot(ridge)
# 
# ridge$lambda.min
# coef(ridge, s = "lambda.min")

```

```{r}
# enet <- cv.glmnet(X, y, alpha=0.5, standardize=FALSE, type.measure = "mse", nfolds = 10)
# 
# plot(enet)
# (enet$lambda.min)
# coef(enet, s = "lambda.min")
```

```{r}
# lasso_mse <- cvfit$cvm[cvfit$lambda == cvfit$lambda.min]
# enet_mse  <- enet$cvm[enet$lambda == enet$lambda.min]
# 
# c(Lasso = lasso_mse,
#   ElasticNet = enet_mse,
#   Ridge = ridge_mse)


```

## Q2:

```{r}
set.seed(123457)
obj <- load("Q2.Rdata")
obj
df2 <- df
# head(df2, 200)
# str(df2)
# summary(df2)
```

|   | MAE | Residual Dev (dof) | Null Dev (dof) | Dispersion Parameter | AIC |
|------------|------------|------------|------------|------------|------------|
| **Poisson** | 22.36857 | 595.90 (35) | 663.57 (39) | 17.025 | 826.4404 |
| **Quasi-Poisson** | 22.36857 | 595.90 (35) | 663.57 (39) | 13.918 | NA |
| **Negative Binomial** | 22.39681 | 44.39 (35) | 47.60 (39) | 2.465 | 394.41 |
| **Negative Binomial (Reduced)** | 22.37500 | 44.40 (35) | 47.45 (39) | 2.456 | 388.55 |

### Fitting the model:

```{r}
library(MASS)
carcar.nbf <- glm.nb(lfc ~ Lat+LBW+ELE+SMR, data = df2)
summary(carcar.nbf)
```

```{r}
carcar.fit <- glm.nb(lfc ~ SMR, data = df2)
summary(carcar.fit)
```

#### Code used for analysis:

```{r}
# carcar.pn <- glm(lfc ~ 1, family = 'poisson', data = df2)
# summary(carcar.pn)
# carcar.pf <- glm(lfc ~ Lat+LBW+ELE+SMR, family = 'poisson', data = df2)
# summary(carcar.pf)
```

```{r}
# AIC(carcar.pn, carcar.pf)
# (disp.est <- carcar.pf$deviance/carcar.pf$df.residual)
```

```{r}
# carcar.qpf <- glm(lfc ~ Lat+LBW+ELE+SMR, family = 'quasipoisson', data = df2)
# summary(carcar.qpf)
```

```{r}
# pf <- mean(abs(df2$lfc - fitted(carcar.pf)))
# qpf <- mean(abs(df2$lfc - fitted(carcar.qpf)))
# nbf <- mean(abs(df2$lfc - fitted(carcar.nbf)))
# 
# less <- mean(abs(df2$lfc - fitted(carcar.less)))
# 
# 
# MAE_list <- c(
#   Poisson               = pf,
#   QuasiPoisson          = qpf,
#   NegativeBinomial      = nbf,
#   ReducedPoisson        = less,
# )
# 
# (MAE_table <- data.frame(Model = names(MAE_list),MAE   = as.numeric(MAE_list)))
```

```{r}
# carcar.nbn <- glm.nb(lfc ~ 1, data = df2)
# (an.nb <- anova(carcar.nbn, carcar.nbf))
# print(an.nb$`Pr(Chi)`[2]) 
```

```{r}
# hist(df2$lfc, breaks=30, main="", xlab="y")
```

## Q3:

```{r}
obj <- load("Q3.Rdata")
df3 <- df
# head(df3, 100)
# str(df3)
# table(df3$y)
```

```{r}
#df3$y <- as.factor(ifelse(df3$y == "1", 1, 0))
col_class <- sapply(1:ncol(df3), function(x) class(df3[, x]))

set.seed(123457)
train.prop <- 0.80
strats <- df3$y
rr <- split(1:length(strats), strats)
idx <- sort(as.numeric(unlist(sapply(rr, 
        function(x) sample(x, length(x)*train.prop)))))
df3.train <- df3[idx, ]
df3.test <- df3[-idx, ]

```

### Final Model:

```{r}
library(ranger)
fit.rf.ranger <- ranger(y ~ ., data = df3.train, probability = FALSE, classification = TRUE, importance = 'impurity', mtry = 3)
# 
# summary(fit.rf.rangprint(fit.rf.ranger)er)
```

```{r}
#install.packages("vip")
library(vip)
(v1 <- vi(fit.rf.ranger))
vip(v1)
```

```{r}
pred <- predict(fit.rf.ranger, data = df3.test)
test_df <- data.frame(actual = df3.test$y, pred = NA)
test_df$pred <- pred$predictions
(conf_matrix_rf <- table(test_df$pred, test_df$actual))
```

#### Model Comparison:

|                               | Accuracy | Sensitivity | Specificity |
|-------------------------------|----------|-------------|-------------|
| **Full Logit**                | .760     | .870        | .361        |
| **Stepwise Function (Logit)** | .770     | .875        | .389        |
| **CART**                      | .994     | .996        | .987        |
| **Random Forest**             | .998     | .999        | .991        |
| **XGBoost**                   | .998     | .999        | .991        |
| **SVM**                       | .549     | .863        | .283        |

#### Code used for analysis:

```{r}
# #| dpi: 300
# #| fig.width: 7
# #| fig.height: 5
# 
# 
# num_vars <- c("x1","x2","x3")
# 
# par(mfrow = c(2, 2))
# for (v in num_vars) {
# hist(df3[[v]],
# main = paste("Histogram of", v),
# xlab = v,
# col = "blue",
# border = "white")}
# 
# boxplot(df3[, num_vars],
# main = "Boxplots of Predictors x1â€“x3",
# ylab = "Value",
# col="purple")
```

```{r}
# set.seed(123457)
# full.logit <- glm(y ~ . ,data = df3.train, family = binomial(link = "logit"))
# null.logit <- glm(y ~ 1, data = df3.train, family = binomial(link = "logit"))
# 
# summary(full.logit)
# summary(null.logit)
```

```{r}
# both.logit <- step(null.logit, list(lower = formula(null.logit),upper = formula(full.logit)), direction = "both", trace = 0, data = df3.train)
# summary(both.logit)
```

```{r}
# pred.both <- predict(both.logit, newdata = df3.test, type = "response")
# pred.full <- predict(full.logit, newdata = df3.test, type = "response")
# 
# (table.both <- table(pred.both > 0.70, df3.test$y))
# (table.full <- table(pred.full > 0.70, df3.test$y))
# 
# (accuracy.both <- round((sum(diag(table.both))/sum(table.both))*100, 3)) 
# (accuracy.full <- round((sum(diag(table.full))/sum(table.full))*100, 3))
```

```{r}
# library(caret)
# f <- ifelse(pred.both > 0.75, 1, 0)
# (cm.both <- confusionMatrix(reference = as.factor(df3.test$y), 
#             data = as.factor(f), mode = "everything"))
```

```{r}
# #| dpi: 300
# #| fig.width: 7
# #| fig.height: 5
# library(pROC)
# par(mfrow = c(1,1))
# roc.both <- roc(df3.test$y ~ pred.both, plot = TRUE,
#                 legacy.axes = TRUE, print.auc = TRUE)
```

#### CART:

```{r}
# library(rpart)
# cart <- rpart(y ~., method = "class", data = df3.train,control = rpart.control(minsplit = 1, cp = 0.001))
# (rootnode_err <- sum(df3.train$y==1)/nrow(df3.train))
# printcp(cart)
```

For what value of CP is xerror the smallest?

```{r}
# (cp <- cart$cptable[which.min(cart$cptable[, "xerror"]), "CP"])
```

```{r}
# #| dpi: 300
# #| fig.width: 7
# #| fig.height: 5
# plotcp(cart)
```

```{r}
# test_df <- data.frame(actual = df3.test$y, pred = NA)
# test_df$pred <- predict(cart, newdata = df3.test, type = "class")
# (conf_matrix_base <- table(test_df$pred, test_df$actual))
```

```{r}
# library(caret)
# sensitivity(conf_matrix_base)
# specificity(conf_matrix_base)
# (mis.rate <- conf_matrix_base[1, 2] + conf_matrix_base[2, 1])/sum(conf_matrix_base) 
```

```{r}
# cart2 <- prune(cart, cp = cart$cptable[which.min(cart$cptable[, "xerror"]), "CP"])
# test_df$pred <- predict(cart2, newdata = df3.test, type = "class")
# (conf_matrix_pruned <- table(test_df$pred, test_df$actual))
```

```{r}
# library(rpart.plot)
# rpart.plot(cart2, extra = "auto")
# summary(cart2)
```

```{r}
# (xerr.pfit <- cart2$cptable[which.min(cart2$cptable[, "xerror"]), "xerror"])
```

```{r}
# library(caret)
# sensitivity(conf_matrix_pruned)
# specificity(conf_matrix_pruned)
# (conf_matrix_pruned[1, 2] + conf_matrix_pruned[2, 1])/sum(conf_matrix_pruned) 
```

#### Random Forest:

```{r}
# library(caret)
# sensitivity(conf_matrix_rf)
# specificity(conf_matrix_rf)
# (mis.rate <- conf_matrix_rf[1, 2] + conf_matrix_rf[2, 1])/sum(conf_matrix_rf) 

```

#### XGBoost:

```{r}
# library(xgboost)
# library(Matrix)
# 
# matrix_predictors.train <- as.matrix(sparse.model.matrix(y ~., data = df3.train))[, -1]
# matrix_predictors.test <- as.matrix(sparse.model.matrix(y ~., data = df3.test))[, -1]
```

```{r}
# pred.train.gbm <- data.matrix(matrix_predictors.train)
# df3.train.gbm <- as.numeric(as.character(df3.train$y)) 
# dtrain <- xgb.DMatrix(data = pred.train.gbm, label = df3.train.gbm)
# 
# pred.test.gbm <- data.matrix(matrix_predictors.test)
# df3.test.gbm <- as.numeric(as.character(df3.test$y))
# dtest <- xgb.DMatrix(data = pred.test.gbm, label = df3.test.gbm)
```

```{r}
# watchlist <- list(train = dtrain, test = dtest)
# param <- list(max_depth = 2, eta = 1, nthread = 2, objective = "binary:logistic", eval_metric = "auc")
# 
# model.xgb <- xgb.train(param, dtrain, nrounds = 2, watchlist)
```

```{r}
# pred.y.train <- predict(model.xgb, pred.train.gbm)
# prediction.train <- as.numeric(pred.y.train > 0.7)
# 
# (tab<-table(df3.train.gbm, prediction.train))
```

```{r}
# library(caret)
# conf_matrix_gb <- table(test_df$pred, test_df$actual)
# conf_matrix_gb
# sensitivity(conf_matrix_gb)
# specificity(conf_matrix_gb)
# (conf_matrix_gb[1,2] + conf_matrix_gb[2,1])/sum(conf_matrix_gb) 
```

#### SVM:

```{r}
# library(e1071)
# 
# df3.train$y <- factor(df3.train$y)
# df3.test$y  <- factor(df3.test$y, levels = c(0,1))
# 
# mod.svm <- svm(y ~ ., data = df3.train, kernel = "radial")
# 
# 
# svm_pred <- predict(mod.svm, newdata = df3.test)
# 
# test_df <- data.frame(actual = df3.test$y, pred = svm_pred)
# conf_matrix_svm <- table(test_df$pred, test_df$actual)
# conf_matrix_svm
# 
# library(caret)
# sensitivity(conf_matrix_svm)
# specificity(conf_matrix_svm)
# (conf_matrix_svm[1, 2] + conf_matrix_svm[2, 1]) / sum(conf_matrix_svm)

```
